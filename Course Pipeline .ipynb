{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddd06f7-3837-4ef9-8d70-cfe075736595",
   "metadata": {},
   "source": [
    "# IST769 Final Exam\n",
    "\n",
    "**INSTRUCTIONS FOR HIGHEST GRADE POSSIBLE**\n",
    "\n",
    "Unless you are explicitly instructed otherwise, answer each of the following using PySpark / Spark SQL. For any queries you write make sure to include a `printSchema()` and sample(s) of the output which clearly demonstrates the code is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25feebd0-d09b-4233-b9af-ec965875930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp /home/jovyan/work/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar /usr/local/spark/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4308c98a-a418-4120-9ee7-05992d21e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c73c8d6-8ab6-44a8-8a78-51598b8c07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12353bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NAME ========>  SAITEJA NAMANI\n",
    "# YOUR SU EMAIL ====>  snamani@syr.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91718b91-ceae-416d-b96c-053a5d844676",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "In the cell below configure a spark session that is configured to connect to `mongodb`, `minio`, `cassandra`, '`elasticsearch` and `neo4j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5ecf9f-0798-4bc9-8896-229a0faade48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Spark session\n",
    "\n",
    "cassandra_host = \"cassandra\"\n",
    "user = \"minio\"\n",
    "passwd = \"SU2orange!\"\n",
    "s3_bucket = \"gamestreams\"\n",
    "s3_server = \"http://minio:9000\"\n",
    "s3_access_key = user\n",
    "s3_secret_key = passwd\n",
    "mongo_uri = \"mongodb://admin:mongopw@mongo:27017/demo.feedback?authSource=admin\"\n",
    "elastic_host = \"elasticsearch\"\n",
    "elastic_port = \"9200\"\n",
    "\n",
    "bolt_url = \"bolt://neo4j:7687\"\n",
    "\n",
    "jars = [\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\",\n",
    "    \"org.elasticsearch:elasticsearch-spark-20_2.12:7.15.0\"\n",
    "]\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "        .config(\"spark.jars.packages\",\",\".join(jars)) \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", s3_server ) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.es.nodes\", elastic_host) \\\n",
    "        .config(\"spark.es.port\",elastic_port) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee055a5-7a8f-4739-a3f5-a52d981ea05e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Demonstrate you can read the process-oriented data `enrollments` and `sections` from `minio` using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50367be-c7ac-43b0-b820-54e4b7d83c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Top 10 rows of the Enrollment data frame ---------\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|term|course_enrollment|course|section|       student_id|grade|grade_points|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|1221|                1|IST659|   M001|      orenjouglad|    C|         2.0|\n",
      "|1221|                2|IST659|   M001|      billmelator|    A|         4.0|\n",
      "|1221|                3|IST659|   M001|       morrisless|    A|         4.0|\n",
      "|1221|                4|IST659|   M001|amberwavesofgrain|   A-|       3.667|\n",
      "|1221|                5|IST659|   M001|         abbykuss|    A|         4.0|\n",
      "|1221|                6|IST659|   M001|       tallyitupp|    A|         4.0|\n",
      "|1221|                7|IST659|   M001|     rubyslippers|   B-|       2.667|\n",
      "|1221|                8|IST659|   M001|          salladd|   A-|       3.667|\n",
      "|1221|                9|IST659|   M001|isabellegunnering|    A|         4.0|\n",
      "|1221|               10|IST659|   M001|        rustycarz|    B|         3.0|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------- Schema of enrollments ------\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2a enrollments\n",
    "#Reading enrollments data from MinIO\n",
    "df_enrollments = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"s3a://enrollments/enrollments.csv\")\n",
    "\n",
    "print(\"--------- Top 10 rows of the Enrollment data frame ---------\")\n",
    "#Displaying the top 10 rows of the data frame\n",
    "df_enrollments.show(10)\n",
    "print(\"------- Schema of enrollments ------\")\n",
    "#Printing the schema of the enrollments data frame\n",
    "df_enrollments.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b415479-5acf-42dc-b535-c80bc62d239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 rows of the Sections data frame -\n",
      "+----+------+-------+----------+--------+\n",
      "|term|course|section|enrollment|capacity|\n",
      "+----+------+-------+----------+--------+\n",
      "|1221|IST659|   M001|        20|      20|\n",
      "|1221|IST659|   M002|        20|      20|\n",
      "|1221|IST722|   M001|        25|      28|\n",
      "|1221|IST615|   M001|        22|      28|\n",
      "|1221|IST621|   M001|        22|      24|\n",
      "|1221|IST687|   M001|        20|      20|\n",
      "|1221|IST687|   M002|        21|      24|\n",
      "|1221|IST707|   M001|        28|      28|\n",
      "|1222|IST659|   M001|        24|      24|\n",
      "|1222|IST769|   M001|        19|      24|\n",
      "+----+------+-------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------- Schema of Sections ------\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2b sections \n",
    "#Reading Sections data from MinIO\n",
    "df_sections = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"s3a://enrollments/sections.csv\")\n",
    "\n",
    "\n",
    "#Displaying the top 10 rows of the data frame\n",
    "print(\"- Top 10 rows of the Sections data frame -\")\n",
    "df_sections.show(10)\n",
    "#Printing the schema of the Sections data frame\n",
    "print(\"------- Schema of Sections ------\")\n",
    "df_sections.printSchema()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74906498-d775-451f-befd-5e88595b7009",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Demonstrate you can read the reference-oriented data `terms`, `students`, `courses`, and `program` reference data from `MongoDb` using PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f928bc1-1306-42d7-a073-c7673dde4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 rows of the teams  -\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "| _id|academic_year|code|       name|semester|year|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "|1221|    2021-2022|1221|  Fall 2021|    Fall|2021|\n",
      "|1222|    2021-2022|1222|Spring 2022|  Spring|2022|\n",
      "|1231|    2022-2023|1231|  Fall 2022|    Fall|2022|\n",
      "|1232|    2022-2023|1232|Spring 2023|  Spring|2023|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "\n",
      "------- Schema of teams ------\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3a terms \n",
    "# Reading terms from MongoDB\n",
    "df_terms = spark.read.format(\"mongo\")\\\n",
    "            .option(\"database\", \"ischooldb\")\\\n",
    "            .option(\"collection\",\"terms\")\\\n",
    "            .load()\n",
    "\n",
    "print(\"- Top 10 rows of the teams  -\")\n",
    "df_terms.show(10)\n",
    "print(\"------- Schema of teams ------\")\n",
    "df_terms.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b917eaca-2e3e-45ab-84aa-bc2f07bf6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 rows of the courses  -\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|   _id|  code|credits|         description|elective_in_programs| key_assignments|                name|prerequisites|required_in_programs|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|IST659|IST659|      3|Definition, devel...|                  []|       [project]|Data Administrati...|           []|            [IS, DS]|\n",
      "|IST722|IST722|      3|Introduction to c...|                [IS]| [project, exam]|    Data Warehousing|     [IST659]|                  []|\n",
      "|IST769|IST769|      3|Analyze relationa...|                [DS]| [project, exam]|Advanced Big Data...|     [IST659]|                  []|\n",
      "|IST615|IST615|      3|Cloud services cr...|                  []|[project, paper]|    Cloud Management|           []|            [IS, DS]|\n",
      "|IST714|IST714|      3|Advanced, lab-bas...|            [IS, DS]|       [project]|  Cloud Architecture|     [IST615]|                  []|\n",
      "|IST621|IST621|      3|Information and t...|                  []|         [paper]|Information Manag...|           []|                [IS]|\n",
      "|IST687|IST687|      3|Introduces inform...|                [IS]| [project, exam]|Introduction to D...|           []|                [DS]|\n",
      "|IST707|IST707|      3|General overview ...|                [IS]|          [exam]|Applied Machine L...|     [IST687]|                [DS]|\n",
      "|IST718|IST718|      3|A broad introduct...|                  []|       [project]|  Big Data Analytics|     [IST687]|                [DS]|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "\n",
      "------- Schema of courses ------\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3b courses\n",
    "# Reading courses from MongoDB\n",
    "df_courses = spark.read.format(\"mongo\")\\\n",
    "            .option(\"database\", \"ischooldb\")\\\n",
    "            .option(\"collection\",\"courses\")\\\n",
    "            .load()\n",
    "\n",
    "print(\"- Top 10 rows of the courses  -\")\n",
    "df_courses.show(10)\n",
    "print(\"------- Schema of courses ------\")\n",
    "df_courses.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f483a03-3da6-4efa-95d7-06c82e556400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 rows of the programs  -\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "|_id|code|credits|    elective_courses|                name|    required_courses|       type|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "| IS|  IS|     36|[IST722, IST714, ...| Information Systems|[IST659, IST615, ...|    Masters|\n",
      "| DS|  DS|     34|    [IST769, IST714]|        Data Science|[IST659, IST615, ...|    Masters|\n",
      "|BDC| BDC|      9|                null|Data Engineering ...|[IST659, IST722, ...|Certificate|\n",
      "|CCC| CCC|      9|                null|Cloud Computing C...|[IST621, IST615, ...|Certificate|\n",
      "|MLC| MLC|      9|                null|Machine Learning ...|[IST687, IST707, ...|Certificate|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "\n",
      "------- Schema of programs ------\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3c Programs\n",
    "# Reading Programs from MongoDB\n",
    "df_programs = spark.read.format(\"mongo\")\\\n",
    "            .option(\"database\", \"ischooldb\")\\\n",
    "            .option(\"collection\",\"programs\")\\\n",
    "            .load()\n",
    "\n",
    "print(\"- Top 10 rows of the programs  -\")\n",
    "df_programs.show(10)\n",
    "print(\"------- Schema of programs ------\")\n",
    "df_programs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d87294-61eb-4dd4-8b7a-5c280b6b7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 rows of the students  -\n",
      "+---------------+----------------+-------+\n",
      "|            _id|            name|program|\n",
      "+---------------+----------------+-------+\n",
      "|       abbykuss|       Abby Kuss|     DS|\n",
      "|     adamantium|     Adam Antium|     IS|\n",
      "|      addieowse|      Addie Owse|     IS|\n",
      "|   aidensomewun|   Aiden Somewun|     IS|\n",
      "|   aidenknowone|   Aiden Knowone|     DS|\n",
      "|       alfrecso|       Al Frecso|     DS|\n",
      "|        alkohol|        Al Kohol|     DS|\n",
      "|    allanwrench|    Allan Wrench|     IS|\n",
      "|      allygator|      Ally Gator|     IS|\n",
      "|almafrienzergon|Alma Frienzergon|     IS|\n",
      "+---------------+----------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------- Schema of students ------\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- program: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3d students\n",
    "# Reading students from MongoDB\n",
    "df_students = spark.read.format(\"mongo\")\\\n",
    "            .option(\"database\", \"ischooldb\")\\\n",
    "            .option(\"collection\",\"students\")\\\n",
    "            .load()\n",
    "\n",
    "print(\"- Top 10 rows of the students  -\")\n",
    "df_students.show(10)\n",
    "print(\"------- Schema of students ------\")\n",
    "df_students.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfca28-8272-46ee-b98c-6a263be01c56",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Prepare the `section` data for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. Just PREPARE it do not LOAD it. Remember that we want this data to be as wide as possible, so include all relevant reference data. For example, the `section` data should include `term` attributes like `year`,  `academic year`, etc... and from `course`, attributes like `credits`, `name`, `prerequisites`, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8a9218-9dc1-4e69-87d8-90274d579ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Schema of wide section ------\n",
      "root\n",
      " |-- term_code: integer (nullable = true)\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "------- Top 10 rows of the Wide sections ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:==================================================>    (91 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+----------+--------+-------------+--------+---------+--------------------+--------------+--------------------+-------------+\n",
      "|term_code|course_code|section|enrollment|capacity|academic_year|semester|term_year|         course_name|course_credits|  course_description|prerequisites|\n",
      "+---------+-----------+-------+----------+--------+-------------+--------+---------+--------------------+--------------+--------------------+-------------+\n",
      "|     1221|     IST615|   M001|        22|      28|    2021-2022|    Fall|     2021|    Cloud Management|             3|Cloud services cr...|           []|\n",
      "|     1222|     IST615|   M001|        19|      24|    2021-2022|  Spring|     2022|    Cloud Management|             3|Cloud services cr...|           []|\n",
      "|     1231|     IST615|   M001|        21|      24|    2022-2023|    Fall|     2022|    Cloud Management|             3|Cloud services cr...|           []|\n",
      "|     1232|     IST615|   M002|        20|      24|    2022-2023|  Spring|     2023|    Cloud Management|             3|Cloud services cr...|           []|\n",
      "|     1232|     IST615|   M001|        21|      28|    2022-2023|  Spring|     2023|    Cloud Management|             3|Cloud services cr...|           []|\n",
      "|     1221|     IST659|   M002|        20|      20|    2021-2022|    Fall|     2021|Data Administrati...|             3|Definition, devel...|           []|\n",
      "|     1221|     IST659|   M001|        20|      20|    2021-2022|    Fall|     2021|Data Administrati...|             3|Definition, devel...|           []|\n",
      "|     1222|     IST659|   M001|        24|      24|    2021-2022|  Spring|     2022|Data Administrati...|             3|Definition, devel...|           []|\n",
      "|     1231|     IST659|   M002|        20|      20|    2022-2023|    Fall|     2022|Data Administrati...|             3|Definition, devel...|           []|\n",
      "|     1231|     IST659|   M001|        20|      20|    2022-2023|    Fall|     2022|Data Administrati...|             3|Definition, devel...|           []|\n",
      "+---------+-----------+-------+----------+--------+-------------+--------+---------+--------------------+--------------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#4 wide_sections\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Registering DataFrames as temporary views\n",
    "for df, name in [(df_sections, \"sections\"), (df_terms, \"terms\"), \n",
    "                 (df_courses, \"courses\"), (df_programs, \"programs\"), \n",
    "                 (df_students, \"students\")]:\n",
    "    df.createOrReplaceTempView(name)\n",
    "\n",
    "# The SQL query for the join operation\n",
    "query1 = \"\"\"\n",
    "SELECT s.term as term_code, s.course as course_code, s.section, s.enrollment, s.capacity,\n",
    "       t.academic_year, t.semester, t.year as term_year,\n",
    "       c.name as course_name, c.credits as course_credits, c.description as course_description, c.prerequisites\n",
    "FROM sections s\n",
    "INNER JOIN terms t ON s.term = t.code\n",
    "INNER JOIN courses c ON s.course = c.code\n",
    "\"\"\"\n",
    "\n",
    "# Executing the SQL query\n",
    "wide_column = spark.sql(query1)\n",
    "\n",
    "# Printing the schema and display the data\n",
    "print(\"------- Schema of wide section ------\")\n",
    "wide_column.printSchema()\n",
    "print(\"------- Top 10 rows of the Wide sections ------\")\n",
    "wide_column.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f972cf-8ab1-48fe-b2ff-607acc11e05d",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Use the `cassandra-driver` example from class to write python code to connect to cassandra from within Jupyter and create a keyspace named `ischooldb`. Design a cassandra table called `sections` to store the data from question 4. Appropriate key design is important! Please explain your justification for key below your table definition. Provide clear evidence that your table was created by querying the empty table in spark and use `printSchema()` to show the schema. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4015e68d-c1d0-4bb6-962e-f42bdaeb28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 create cassandra table for wide_sections\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS ischooldb WITH replication={ 'class': 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "\n",
    "    session.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ischooldb.sections (term_code text, course_code text, section text, enrollment int, capacity int,\n",
    "        academic_year text,semester text,term_year int,course_name text,course_credits int,course_description text, prerequisites list<text>,\n",
    "        PRIMARY KEY ((term_code, course_code), section)\n",
    "        );\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700e1a1c-602a-4361-bef3-f5919f66812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Schema of sections ------\n",
      "root\n",
      " |-- term_code: string (nullable = false)\n",
      " |-- course_code: string (nullable = false)\n",
      " |-- section: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      "\n",
      "------- Displaying the table of sections cassandra table ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "|term_code|course_code|section|academic_year|capacity|course_credits|  course_description|         course_name|enrollment|prerequisites|semester|term_year|\n",
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "|     1222|     IST714|   M001|    2021-2022|      20|             3|Advanced, lab-bas...|  Cloud Architecture|        17|     [IST615]|  Spring|     2022|\n",
      "|     1222|     IST718|   M001|    2021-2022|      28|             3|A broad introduct...|  Big Data Analytics|        28|     [IST687]|  Spring|     2022|\n",
      "|     1231|     IST722|   M001|    2022-2023|      28|             3|Introduction to c...|    Data Warehousing|        23|     [IST659]|    Fall|     2022|\n",
      "|     1221|     IST621|   M001|    2021-2022|      24|             3|Information and t...|Information Manag...|        22|           []|    Fall|     2021|\n",
      "|     1231|     IST621|   M001|    2022-2023|      28|             3|Information and t...|Information Manag...|        28|           []|    Fall|     2022|\n",
      "|     1222|     IST615|   M001|    2021-2022|      24|             3|Cloud services cr...|    Cloud Management|        19|           []|  Spring|     2022|\n",
      "|     1231|     IST687|   M001|    2022-2023|      20|             3|Introduces inform...|Introduction to D...|        17|           []|    Fall|     2022|\n",
      "|     1231|     IST687|   M002|    2022-2023|      24|             3|Introduces inform...|Introduction to D...|        20|           []|    Fall|     2022|\n",
      "|     1221|     IST687|   M001|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        20|           []|    Fall|     2021|\n",
      "|     1221|     IST687|   M002|    2021-2022|      24|             3|Introduces inform...|Introduction to D...|        21|           []|    Fall|     2021|\n",
      "|     1222|     IST659|   M001|    2021-2022|      24|             3|Definition, devel...|Data Administrati...|        24|           []|  Spring|     2022|\n",
      "|     1232|     IST769|   M001|    2022-2023|      24|             3|Analyze relationa...|Advanced Big Data...|        20|     [IST659]|  Spring|     2023|\n",
      "|     1221|     IST722|   M001|    2021-2022|      28|             3|Introduction to c...|    Data Warehousing|        25|     [IST659]|    Fall|     2021|\n",
      "|     1221|     IST707|   M001|    2021-2022|      28|             3|General overview ...|Applied Machine L...|        28|     [IST687]|    Fall|     2021|\n",
      "|     1232|     IST659|   M001|    2022-2023|      20|             3|Definition, devel...|Data Administrati...|        20|           []|  Spring|     2023|\n",
      "|     1232|     IST714|   M001|    2022-2023|      24|             3|Advanced, lab-bas...|  Cloud Architecture|        20|     [IST615]|  Spring|     2023|\n",
      "|     1232|     IST718|   M001|    2022-2023|      28|             3|A broad introduct...|  Big Data Analytics|        28|     [IST687]|  Spring|     2023|\n",
      "|     1222|     IST687|   M001|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        18|           []|  Spring|     2022|\n",
      "|     1222|     IST687|   M002|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        20|           []|  Spring|     2022|\n",
      "|     1221|     IST659|   M001|    2021-2022|      20|             3|Definition, devel...|Data Administrati...|        20|           []|    Fall|     2021|\n",
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sectionsdf_cas = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"sections\", keyspace=\"ischooldb\") \\\n",
    "    .load()\n",
    "print(\"------- Schema of sections ------\")\n",
    "sectionsdf_cas.printSchema()\n",
    "print(\"------- Displaying the table of sections cassandra table ------\")\n",
    "sectionsdf_cas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71b3b5-03d7-456d-a64f-f3c5f0c93836",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Load the data frame you created in question 4 into the `cassandra` table you created in question 5. Demonstrate the data is in the table by querying back it with PySpark. Make sure you can run the code multiple times and each time it replaces the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59e9aac0-da49-4c82-8e3f-184b5f1d9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "|term_code|course_code|section|academic_year|capacity|course_credits|  course_description|         course_name|enrollment|prerequisites|semester|term_year|\n",
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "|     1221|     IST687|   M001|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        20|           []|    Fall|     2021|\n",
      "|     1221|     IST687|   M002|    2021-2022|      24|             3|Introduces inform...|Introduction to D...|        21|           []|    Fall|     2021|\n",
      "|     1222|     IST659|   M001|    2021-2022|      24|             3|Definition, devel...|Data Administrati...|        24|           []|  Spring|     2022|\n",
      "|     1232|     IST769|   M001|    2022-2023|      24|             3|Analyze relationa...|Advanced Big Data...|        20|     [IST659]|  Spring|     2023|\n",
      "|     1221|     IST722|   M001|    2021-2022|      28|             3|Introduction to c...|    Data Warehousing|        25|     [IST659]|    Fall|     2021|\n",
      "|     1221|     IST707|   M001|    2021-2022|      28|             3|General overview ...|Applied Machine L...|        28|     [IST687]|    Fall|     2021|\n",
      "|     1232|     IST659|   M001|    2022-2023|      20|             3|Definition, devel...|Data Administrati...|        20|           []|  Spring|     2023|\n",
      "|     1232|     IST714|   M001|    2022-2023|      24|             3|Advanced, lab-bas...|  Cloud Architecture|        20|     [IST615]|  Spring|     2023|\n",
      "|     1232|     IST718|   M001|    2022-2023|      28|             3|A broad introduct...|  Big Data Analytics|        28|     [IST687]|  Spring|     2023|\n",
      "|     1222|     IST687|   M001|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        18|           []|  Spring|     2022|\n",
      "|     1222|     IST687|   M002|    2021-2022|      20|             3|Introduces inform...|Introduction to D...|        20|           []|  Spring|     2022|\n",
      "|     1221|     IST659|   M001|    2021-2022|      20|             3|Definition, devel...|Data Administrati...|        20|           []|    Fall|     2021|\n",
      "|     1221|     IST659|   M002|    2021-2022|      20|             3|Definition, devel...|Data Administrati...|        20|           []|    Fall|     2021|\n",
      "|     1232|     IST615|   M001|    2022-2023|      28|             3|Cloud services cr...|    Cloud Management|        21|           []|  Spring|     2023|\n",
      "|     1232|     IST615|   M002|    2022-2023|      24|             3|Cloud services cr...|    Cloud Management|        20|           []|  Spring|     2023|\n",
      "|     1231|     IST707|   M001|    2022-2023|      24|             3|General overview ...|Applied Machine L...|        24|     [IST687]|    Fall|     2022|\n",
      "|     1222|     IST769|   M001|    2021-2022|      24|             3|Analyze relationa...|Advanced Big Data...|        19|     [IST659]|  Spring|     2022|\n",
      "|     1221|     IST615|   M001|    2021-2022|      28|             3|Cloud services cr...|    Cloud Management|        22|           []|    Fall|     2021|\n",
      "|     1232|     IST621|   M001|    2022-2023|      28|             3|Information and t...|Information Manag...|        28|           []|  Spring|     2023|\n",
      "|     1232|     IST621|   M002|    2022-2023|      24|             3|Information and t...|Information Manag...|        21|           []|  Spring|     2023|\n",
      "+---------+-----------+-------+-------------+--------+--------------+--------------------+--------------------+----------+-------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6 load wide_sections into cassandra\n",
    "\n",
    "# Write the DataFrame into the 'sections' table in the 'ischooldb' keyspace\n",
    "wide_column.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .option(\"keyspace\", \"ischooldb\") \\\n",
    "    .option(\"table\", \"sections\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "# Reading the data back from the 'sections' table.\n",
    "sectionsdf_cas = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .option(\"keyspace\", \"ischooldb\") \\\n",
    "    .option(\"table\", \"sections\") \\\n",
    "    .load()\n",
    "\n",
    "# Display the data that we have loaded\n",
    "sectionsdf_cas.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052fbcc-b7cc-4fa7-ba5d-09b3066c8b96",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Since we did not learn how to create a custom elasticsearch mapping, before you can load the data into `elasticsearch` you will need to flatten the nested data. For example, `course_is_elective_in_programs` should generate 2 columns `course_is_elective_for_IS` and `course_is_elective_for_DS`. You'll need to repeat this step for `course_is_required_in_programs`. Omit the `course_prerequisites` and `course_key_assignments` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f91002-2880-4f4c-8392-9b869ce42172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Schema ------\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course_is_elective_for_IS: boolean (nullable = false)\n",
      " |-- course_is_elective_for_DS: boolean (nullable = false)\n",
      " |-- course_is_required_for_IS: boolean (nullable = false)\n",
      " |-- course_is_required_for_DS: boolean (nullable = false)\n",
      "\n",
      "------- Data Frame ------\n",
      "+------+------+-------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|   _id|  code|credits|         description|                name|course_is_elective_for_IS|course_is_elective_for_DS|course_is_required_for_IS|course_is_required_for_DS|\n",
      "+------+------+-------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|IST659|IST659|      3|Definition, devel...|Data Administrati...|                    false|                    false|                     true|                     true|\n",
      "|IST722|IST722|      3|Introduction to c...|    Data Warehousing|                     true|                    false|                    false|                    false|\n",
      "|IST769|IST769|      3|Analyze relationa...|Advanced Big Data...|                    false|                     true|                    false|                    false|\n",
      "|IST615|IST615|      3|Cloud services cr...|    Cloud Management|                    false|                    false|                     true|                     true|\n",
      "|IST714|IST714|      3|Advanced, lab-bas...|  Cloud Architecture|                     true|                     true|                    false|                    false|\n",
      "|IST621|IST621|      3|Information and t...|Information Manag...|                    false|                    false|                     true|                    false|\n",
      "|IST687|IST687|      3|Introduces inform...|Introduction to D...|                     true|                    false|                    false|                     true|\n",
      "|IST707|IST707|      3|General overview ...|Applied Machine L...|                     true|                    false|                    false|                     true|\n",
      "|IST718|IST718|      3|A broad introduct...|  Big Data Analytics|                    false|                    false|                    false|                     true|\n",
      "+------+------+-------+--------------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7 flatten `course_is_elective_in_programs` and `course_is_required_in_programs` \n",
    "\n",
    "from pyspark.sql.functions import col, when, array_contains\n",
    "\n",
    "\n",
    "# Defining a function to create new columns for each program\n",
    "def add_program_columns(df, programs, column_name):\n",
    "    for program in programs:\n",
    "        df = df.withColumn(\n",
    "            f\"course_is_{column_name}_for_{program}\",\n",
    "            when(array_contains(col(column_name + \"_in_programs\"), program), True).otherwise(False)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Apply the function for 'elective' and 'required'\n",
    "df_courses = add_program_columns(df_courses, [\"IS\", \"DS\"], \"elective\")\n",
    "df_courses = add_program_columns(df_courses, [\"IS\", \"DS\"], \"required\")\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = [\"elective_in_programs\", \"required_in_programs\", \"prerequisites\", \"key_assignments\"]\n",
    "df_courses = df_courses.drop(*columns_to_drop)\n",
    "\n",
    "# Display the schema and the data to verify the transformations\n",
    "print(\"------- Schema ------\")\n",
    "df_courses.printSchema()\n",
    "print(\"------- Data Frame ------\")\n",
    "df_courses.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd3d88-efe9-4d0c-90ce-941ef6de84e2",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Load the data frame you created in question 7 into `elasticsearch`, under the index `sections`.  Demonstrate the data is in the index by querying back it with PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d2c484-7857-4064-a60c-c1ec0004b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+-------------------------+-------------------------+-------------------------+-------+--------------------+--------------------+\n",
      "|  code|course_is_elective_for_DS|course_is_elective_for_IS|course_is_required_for_DS|course_is_required_for_IS|credits|         description|                name|\n",
      "+------+-------------------------+-------------------------+-------------------------+-------------------------+-------+--------------------+--------------------+\n",
      "|IST659|                    false|                    false|                     true|                     true|      3|Definition, devel...|Data Administrati...|\n",
      "|IST722|                    false|                     true|                    false|                    false|      3|Introduction to c...|    Data Warehousing|\n",
      "|IST769|                     true|                    false|                    false|                    false|      3|Analyze relationa...|Advanced Big Data...|\n",
      "|IST615|                    false|                    false|                     true|                     true|      3|Cloud services cr...|    Cloud Management|\n",
      "|IST714|                     true|                     true|                    false|                    false|      3|Advanced, lab-bas...|  Cloud Architecture|\n",
      "|IST621|                    false|                    false|                    false|                     true|      3|Information and t...|Information Manag...|\n",
      "|IST687|                    false|                     true|                     true|                    false|      3|Introduces inform...|Introduction to D...|\n",
      "|IST707|                    false|                     true|                     true|                    false|      3|General overview ...|Applied Machine L...|\n",
      "|IST718|                    false|                    false|                     true|                    false|      3|A broad introduct...|  Big Data Analytics|\n",
      "+------+-------------------------+-------------------------+-------------------------+-------------------------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8 load wide_sections_flattened into elasticsearch\n",
    "\n",
    "# Remove the '_id' field if it's not necessary for your Elasticsearch documents\n",
    "df_courses = df_courses.drop(\"_id\")\n",
    "\n",
    "# Write the DataFrame to Elasticsearch, using the 'code' field as the document ID\n",
    "df_courses.write \\\n",
    "    .format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .option(\"es.resource\", '{index}/{type}'.format(index=\"sections\", type=\"_doc\")) \\\n",
    "    .option(\"es.mapping.id\", \"code\") \\\n",
    "    .option(\"es.nodes\", elastic_host) \\\n",
    "    .option(\"es.port\", elastic_port) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "# Read back the data to verify\n",
    "df_sections = spark.read \\\n",
    "    .format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .option(\"es.resource\", '{index}/{type}'.format(index=\"sections\", type=\"_doc\")) \\\n",
    "    .option(\"es.nodes\", elastic_host) \\\n",
    "    .option(\"es.port\", elastic_port) \\\n",
    "    .load()\n",
    "\n",
    "df_sections.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa738b4b-6970-46d4-b5dc-3c766f7fe64b",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Similar to question 4, prepare the `enrollments` for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. For this wide table we want to include the same reference data for `sections` but include the `student` attributes and the `program` data associated with the student. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce4ea5ef-282b-4aca-86c3-5401ef105088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide enrollments Data Schema:\n",
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_type: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      "\n",
      "Wide enrollments Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------+-------+-----------+-----+------------+-------------+-----------+--------+---------+--------------------+--------------+--------------------+--------------------+----------------+------------+------------+------------+------------+---------------+\n",
      "|term|course_enrollment|course|section| student_id|grade|grade_points|academic_year|  term_name|semester|term_year|         course_name|course_credits|  course_description|    required_courses|elective_courses|student_name|program_name|program_type|program_code|program_credits|\n",
      "+----+-----------------+------+-------+-----------+-----+------------+-------------+-----------+--------+---------+--------------------+--------------+--------------------+--------------------+----------------+------------+------------+------------+------------+---------------+\n",
      "|1231|               12|IST615|   M001| artiechoke|    A|         4.0|    2022-2023|  Fall 2022|    Fall|     2022|    Cloud Management|             3|Cloud services cr...|[IST659, IST615, ...|[IST769, IST714]| Artie Choke|Data Science|     Masters|          DS|             34|\n",
      "|1231|               18|IST659|   M002| artiechoke|    A|         4.0|    2022-2023|  Fall 2022|    Fall|     2022|Data Administrati...|             3|Definition, devel...|[IST659, IST615, ...|[IST769, IST714]| Artie Choke|Data Science|     Masters|          DS|             34|\n",
      "|1231|                6|IST687|   M002| artiechoke|    A|         4.0|    2022-2023|  Fall 2022|    Fall|     2022|Introduction to D...|             3|Introduces inform...|[IST659, IST615, ...|[IST769, IST714]| Artie Choke|Data Science|     Masters|          DS|             34|\n",
      "|1232|               21|IST621|   M001| artiechoke|    A|         4.0|    2022-2023|Spring 2023|  Spring|     2023|Information Manag...|             3|Information and t...|[IST659, IST615, ...|[IST769, IST714]| Artie Choke|Data Science|     Masters|          DS|             34|\n",
      "|1222|               18|IST615|   M001| peteterpan|    A|         4.0|    2021-2022|Spring 2022|  Spring|     2022|    Cloud Management|             3|Cloud services cr...|[IST659, IST615, ...|[IST769, IST714]| Pete Terpan|Data Science|     Masters|          DS|             34|\n",
      "|1221|                5|IST687|   M001| peteterpan|   B+|       3.333|    2021-2022|  Fall 2021|    Fall|     2021|Introduction to D...|             3|Introduces inform...|[IST659, IST615, ...|[IST769, IST714]| Pete Terpan|Data Science|     Masters|          DS|             34|\n",
      "|1221|               28|IST707|   M001| peteterpan|    A|         4.0|    2021-2022|  Fall 2021|    Fall|     2021|Applied Machine L...|             3|General overview ...|[IST659, IST615, ...|[IST769, IST714]| Pete Terpan|Data Science|     Masters|          DS|             34|\n",
      "|1232|               27|IST718|   M001| peteterpan|   A-|       3.667|    2022-2023|Spring 2023|  Spring|     2023|  Big Data Analytics|             3|A broad introduct...|[IST659, IST615, ...|[IST769, IST714]| Pete Terpan|Data Science|     Masters|          DS|             34|\n",
      "|1232|               10|IST714|   M001| peteterpan|    B|         3.0|    2022-2023|Spring 2023|  Spring|     2023|  Cloud Architecture|             3|Advanced, lab-bas...|[IST659, IST615, ...|[IST769, IST714]| Pete Terpan|Data Science|     Masters|          DS|             34|\n",
      "|1232|                1|IST659|   M001|  camcorder|   A-|       3.667|    2022-2023|Spring 2023|  Spring|     2023|Data Administrati...|             3|Definition, devel...|[IST659, IST615, ...|[IST769, IST714]|  Cam Corder|Data Science|     Masters|          DS|             34|\n",
      "|1221|               15|IST687|   M001|  camcorder|   A-|       3.667|    2021-2022|  Fall 2021|    Fall|     2021|Introduction to D...|             3|Introduces inform...|[IST659, IST615, ...|[IST769, IST714]|  Cam Corder|Data Science|     Masters|          DS|             34|\n",
      "|1221|               21|IST707|   M001|  camcorder|    A|         4.0|    2021-2022|  Fall 2021|    Fall|     2021|Applied Machine L...|             3|General overview ...|[IST659, IST615, ...|[IST769, IST714]|  Cam Corder|Data Science|     Masters|          DS|             34|\n",
      "|1232|                3|IST769|   M001|  camcorder|    A|         4.0|    2022-2023|Spring 2023|  Spring|     2023|Advanced Big Data...|             3|Analyze relationa...|[IST659, IST615, ...|[IST769, IST714]|  Cam Corder|Data Science|     Masters|          DS|             34|\n",
      "|1222|                6|IST718|   M001|  camcorder|   B-|       2.667|    2021-2022|Spring 2022|  Spring|     2022|  Big Data Analytics|             3|A broad introduct...|[IST659, IST615, ...|[IST769, IST714]|  Cam Corder|Data Science|     Masters|          DS|             34|\n",
      "|1222|               22|IST659|   M001|chaselounge|   A-|       3.667|    2021-2022|Spring 2022|  Spring|     2022|Data Administrati...|             3|Definition, devel...|[IST659, IST615, ...|[IST769, IST714]|Chase Lounge|Data Science|     Masters|          DS|             34|\n",
      "|1232|               12|IST687|   M001|chaselounge|    A|         4.0|    2022-2023|Spring 2023|  Spring|     2023|Introduction to D...|             3|Introduces inform...|[IST659, IST615, ...|[IST769, IST714]|Chase Lounge|Data Science|     Masters|          DS|             34|\n",
      "|1231|               22|IST722|   M001|chaselounge|    A|         4.0|    2022-2023|  Fall 2022|    Fall|     2022|    Data Warehousing|             3|Introduction to c...|[IST659, IST615, ...|[IST769, IST714]|Chase Lounge|Data Science|     Masters|          DS|             34|\n",
      "|1232|                1|IST621|   M002|chaselounge|   B-|       2.667|    2022-2023|Spring 2023|  Spring|     2023|Information Manag...|             3|Information and t...|[IST659, IST615, ...|[IST769, IST714]|Chase Lounge|Data Science|     Masters|          DS|             34|\n",
      "|1222|                4|IST615|   M001|  macintosh|    A|         4.0|    2021-2022|Spring 2022|  Spring|     2022|    Cloud Management|             3|Cloud services cr...|[IST659, IST615, ...|[IST769, IST714]|  Mac Intosh|Data Science|     Masters|          DS|             34|\n",
      "|1231|               26|IST621|   M001|  macintosh|    A|         4.0|    2022-2023|  Fall 2022|    Fall|     2022|Information Manag...|             3|Information and t...|[IST659, IST615, ...|[IST769, IST714]|  Mac Intosh|Data Science|     Masters|          DS|             34|\n",
      "+----+-----------------+------+-------+-----------+-----+------------+-------------+-----------+--------+---------+--------------------+--------------+--------------------+--------------------+----------------+------------+------------+------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9 create wide_enrollments\n",
    "\n",
    "df_enrollments.createOrReplaceTempView(\"enrollments\")\n",
    "df_terms.createOrReplaceTempView(\"terms\")\n",
    "df_courses.createOrReplaceTempView(\"courses\")\n",
    "df_programs.createOrReplaceTempView(\"programs\")\n",
    "df_students.createOrReplaceTempView(\"students\")\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT e.*, \n",
    "       t.academic_year, t.name as term_name, t.semester, t.year as term_year,\n",
    "       c.name as course_name, c.credits as course_credits, c.description as course_description, p.required_courses, p.elective_courses,\n",
    "       s.name as student_name, p.name as program_name, p.type as program_type, p.code as program_code, p.credits as program_credits\n",
    "FROM enrollments e\n",
    "JOIN terms t ON e.term = t.code\n",
    "JOIN courses c ON e.course = c.code\n",
    "JOIN students s ON e.student_id = s._id\n",
    "JOIN programs p ON s.program = p.code ;\n",
    "\"\"\"\n",
    "wide_column2 = spark.sql(query2)\n",
    "\n",
    "columns_to_drop = ['_id']\n",
    "wide_column2 = wide_column2.drop(*columns_to_drop)\n",
    "\n",
    "print(\"Wide enrollments Data Schema:\")\n",
    "wide_column2.printSchema()\n",
    "\n",
    "print(\"Wide enrollments Data:\")\n",
    "wide_column2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae284c8-096a-4987-98cf-0800cedced12",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Load the data frame you created in question 8 into `elasticsearch`, under the index `enrollments`. This time, just Omit all array types to make the problem simpler (`elective_courses`, `key_assignments`, `course_prerequisites`, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a42dedc-62c4-4b83-b431-2a3474834901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- course_credits: long (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_enrollment: long (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: float (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_credits: long (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_type: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- term: long (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_year: long (nullable = true)\n",
      "\n",
      "+-------------+------+--------------+--------------------+-----------------+--------------------+-----+------------+------------+---------------+------------+------------+-------+--------+-----------+------------+----+-----------+---------+\n",
      "|academic_year|course|course_credits|  course_description|course_enrollment|         course_name|grade|grade_points|program_code|program_credits|program_name|program_type|section|semester| student_id|student_name|term|  term_name|term_year|\n",
      "+-------------+------+--------------+--------------------+-----------------+--------------------+-----+------------+------------+---------------+------------+------------+-------+--------+-----------+------------+----+-----------+---------+\n",
      "|    2022-2023|IST615|             3|Cloud services cr...|               12|    Cloud Management|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|    Fall| artiechoke| Artie Choke|1231|  Fall 2022|     2022|\n",
      "|    2022-2023|IST659|             3|Definition, devel...|               18|Data Administrati...|    A|         4.0|          DS|             34|Data Science|     Masters|   M002|    Fall| artiechoke| Artie Choke|1231|  Fall 2022|     2022|\n",
      "|    2022-2023|IST687|             3|Introduces inform...|                6|Introduction to D...|    A|         4.0|          DS|             34|Data Science|     Masters|   M002|    Fall| artiechoke| Artie Choke|1231|  Fall 2022|     2022|\n",
      "|    2022-2023|IST621|             3|Information and t...|               21|Information Manag...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|  Spring| artiechoke| Artie Choke|1232|Spring 2023|     2023|\n",
      "|    2021-2022|IST615|             3|Cloud services cr...|               18|    Cloud Management|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|  Spring| peteterpan| Pete Terpan|1222|Spring 2022|     2022|\n",
      "|    2021-2022|IST687|             3|Introduces inform...|                5|Introduction to D...|   B+|       3.333|          DS|             34|Data Science|     Masters|   M001|    Fall| peteterpan| Pete Terpan|1221|  Fall 2021|     2021|\n",
      "|    2021-2022|IST707|             3|General overview ...|               28|Applied Machine L...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|    Fall| peteterpan| Pete Terpan|1221|  Fall 2021|     2021|\n",
      "|    2022-2023|IST718|             3|A broad introduct...|               27|  Big Data Analytics|   A-|       3.667|          DS|             34|Data Science|     Masters|   M001|  Spring| peteterpan| Pete Terpan|1232|Spring 2023|     2023|\n",
      "|    2022-2023|IST714|             3|Advanced, lab-bas...|               10|  Cloud Architecture|    B|         3.0|          DS|             34|Data Science|     Masters|   M001|  Spring| peteterpan| Pete Terpan|1232|Spring 2023|     2023|\n",
      "|    2022-2023|IST659|             3|Definition, devel...|                1|Data Administrati...|   A-|       3.667|          DS|             34|Data Science|     Masters|   M001|  Spring|  camcorder|  Cam Corder|1232|Spring 2023|     2023|\n",
      "|    2021-2022|IST687|             3|Introduces inform...|               15|Introduction to D...|   A-|       3.667|          DS|             34|Data Science|     Masters|   M001|    Fall|  camcorder|  Cam Corder|1221|  Fall 2021|     2021|\n",
      "|    2021-2022|IST707|             3|General overview ...|               21|Applied Machine L...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|    Fall|  camcorder|  Cam Corder|1221|  Fall 2021|     2021|\n",
      "|    2022-2023|IST769|             3|Analyze relationa...|                3|Advanced Big Data...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|  Spring|  camcorder|  Cam Corder|1232|Spring 2023|     2023|\n",
      "|    2021-2022|IST718|             3|A broad introduct...|                6|  Big Data Analytics|   B-|       2.667|          DS|             34|Data Science|     Masters|   M001|  Spring|  camcorder|  Cam Corder|1222|Spring 2022|     2022|\n",
      "|    2021-2022|IST659|             3|Definition, devel...|               22|Data Administrati...|   A-|       3.667|          DS|             34|Data Science|     Masters|   M001|  Spring|chaselounge|Chase Lounge|1222|Spring 2022|     2022|\n",
      "|    2022-2023|IST687|             3|Introduces inform...|               12|Introduction to D...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|  Spring|chaselounge|Chase Lounge|1232|Spring 2023|     2023|\n",
      "|    2022-2023|IST722|             3|Introduction to c...|               22|    Data Warehousing|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|    Fall|chaselounge|Chase Lounge|1231|  Fall 2022|     2022|\n",
      "|    2022-2023|IST621|             3|Information and t...|                1|Information Manag...|   B-|       2.667|          DS|             34|Data Science|     Masters|   M002|  Spring|chaselounge|Chase Lounge|1232|Spring 2023|     2023|\n",
      "|    2021-2022|IST615|             3|Cloud services cr...|                4|    Cloud Management|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|  Spring|  macintosh|  Mac Intosh|1222|Spring 2022|     2022|\n",
      "|    2022-2023|IST621|             3|Information and t...|               26|Information Manag...|    A|         4.0|          DS|             34|Data Science|     Masters|   M001|    Fall|  macintosh|  Mac Intosh|1231|  Fall 2022|     2022|\n",
      "+-------------+------+--------------+--------------------+-----------------+--------------------+-----+------------+------------+---------------+------------+------------+-------+--------+-----------+------------+----+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10 wide_enrollments to elastic search\n",
    "\n",
    "# Exclude the array columns to simplify the DataFrame\n",
    "wide_column3 = wide_column2.drop('elective_courses', 'key_assignments', 'course_prerequisites', 'required_courses')\n",
    "\n",
    "# Writing the DataFrame to Elasticsearch\n",
    "wide_column3.write.format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .option(\"es.resource\", \"enrollments/_doc\") \\\n",
    "    .option(\"es.nodes\", elastic_host) \\\n",
    "    .option(\"es.port\", elastic_port) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "enrollments_from_elastic = spark.read.format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .option(\"es.resource\", \"enrollments/_doc\") \\\n",
    "    .option(\"es.nodes\", elastic_host) \\\n",
    "    .option(\"es.port\", elastic_port) \\\n",
    "    .load()\n",
    "\n",
    "enrollments_from_elastic.printSchema()\n",
    "# Show the data to confirm it's been loaded\n",
    "enrollments_from_elastic.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baf832-3a14-45c9-9594-d607439b845a",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write spark to clear the `neo4j` database of all nodes and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd7a903e-789b-4b01-8501-6041190b50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 reset neo4j database \n",
    "\n",
    "cipher_ql = '''\n",
    "MATCH (n)\n",
    "DETACH DELETE n\n",
    "'''\n",
    "df_neo = spark.createDataFrame(data = [{'row':1}])\n",
    "df_neo.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6910199-edde-418d-b6fa-06c5d810ce3d",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Load the `courses` and `program` data into `neo4j` as nodes. Exclude the `requirements`, `electives` and `prerequisites` from the node attributes. Demonstrate the data in `neo4j` by querying back it using one or more Cypher queries. NOTE: the Neo4J `name` attribute is what will display on the node bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71eeb25c-fa18-4702-9595-34f443aca315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#12a load courses into Neo4j\n",
    "\n",
    "# Define the columns to extract from the DataFrame\n",
    "selected_columns = [\"course\", \"course_name\", \"course_credits\", \"course_description\"]\n",
    "\n",
    "# Select distinct course records\n",
    "unique_courses_df = wide_column3.select(selected_columns).distinct()\n",
    "\n",
    "# Define the Cypher query for creating or merging course nodes in Neo4j\n",
    "cypher_query = \"\"\"\n",
    "MERGE (c:Course {\n",
    "    code: event.course, \n",
    "    name: event.course_name, \n",
    "    credits: event.course_credits, \n",
    "    description: event.course_description\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "# Write the DataFrame to Neo4j using the Neo4j Spark Connector\n",
    "unique_courses_df.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cypher_query) \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69aa723b-5479-4232-aca3-0197e199cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#12b load programs into neo4j\n",
    "\n",
    "# Define the columns to extract from the DataFrame\n",
    "selected_columns2 = [\"program_code\", \"program_name\", \"program_credits\", \"program_type\"]\n",
    "\n",
    "# Select distinct program records\n",
    "unique_programs_df2 = wide_column3.select(selected_columns2).distinct()\n",
    "\n",
    "# Define the Cypher query for creating or merging program nodes in Neo4j\n",
    "cypher_query2 = \"\"\"\n",
    "MERGE (p:Program {\n",
    "    code: event.program_code, \n",
    "    name: event.program_name, \n",
    "    credits: event.program_credits, \n",
    "    type: event.program_type\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "# Write the DataFrame to Neo4j using the Neo4j Spark Connector\n",
    "unique_programs_df2.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cypher_query2) \\\n",
    "    .save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5508275-5202-43f5-8adf-773dc22fc681",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Load the `requirements` and `electives` data into `neo4j` as relationships to the nodes you created in Question 12. Use the `program` data to form the `required` and `elective` course relationships. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0725f90-beab-49a5-aede-3a5aa4505a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_type: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wide_column3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fce34443-6a23-42b6-8695-cd6680a39528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: double (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_type: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wide_column2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f782d89-fa86-4c79-b1f0-baf383c47100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#13a program course requirements\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "required_relationships = wide_column2.select(\"program_code\", explode(\"required_courses\").alias(\"course_code\"))\n",
    "elective_relationships = wide_column2.select(\"program_code\", explode(\"elective_courses\").alias(\"course_code\"))\n",
    "\n",
    "\n",
    "# Defining the Cypher query for creating relationships between programs and required courses\n",
    "cypher_query_required = \"\"\"\n",
    "MERGE (p:Program {code: event.program_code})\n",
    "MERGE (c:Course {code: event.course_code})\n",
    "MERGE (p)-[r:COURSE_REQUIRED]->(c)\n",
    "\"\"\"\n",
    "\n",
    "# Write the DataFrame that represents required relationships to Neo4j\n",
    "required_relationships.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cypher_query_required) \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9abc97bf-a75a-48d9-902a-aae259211e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#13b program course electives\n",
    "\n",
    "# Define the Cypher query for creating relationships between programs and their elective courses\n",
    "cypher_query_elective = \"\"\"\n",
    "MERGE (p:Program {code: event.program_code})\n",
    "MERGE (c:Course {code: event.course_code})\n",
    "MERGE (p)-[r:COURSE_ELECTIVES]->(c)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the write operation to Neo4j, setting elective course relationships\n",
    "elective_relationships.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cypher_query_elective) \\\n",
    "    .save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41643746-9a08-436d-9017-7d0f30585f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- term_code: integer (nullable = true)\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: integer (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wide_column.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad62a7-505a-4bb8-a2bd-3756cf6719d5",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Load the `prerequisites` into `neo4j` as relationships to the `course` nodes you created in Question 12. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e586b-c5be-4908-bc31-26ab6ef5ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 course prerequisites \n",
    "\n",
    "relationships = wide_column2.select(\"course\", explode(\"prerequisites\")\\\n",
    "                                                      .alias(\"prerequisite_course_code\"))\n",
    "\n",
    "cipher_ql_prerequisites = \"\"\"\n",
    "MERGE (c:Course {code: event.course_code})\n",
    "MERGE (pc:Course {code: event.prerequisite_course_code})\n",
    "MERGE (c)-[r:REQUIRES]->(pc)\n",
    "\"\"\"\n",
    "\n",
    "df_prerequisites_relationships.write.format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .option(\"url\", bolt_url) \\\n",
    "    .option(\"query\", cipher_ql_prerequisites) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4d61d-5076-4d6e-9f54-03e437d18333",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Write a Cypher query to display courses which are required by both the `IS` and `DS` programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2252e315-eaba-47ee-9f8e-11fc43529c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMATCH (p1:Program {code: \"IS\"})-[:REQUIRES]->(course:Course),\\n      (p2:Program {code: \"DS\"})-[:REQUIRES]->(course)\\nRETURN course.code AS CourseCode, course.name AS CourseName\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15 Cypher query courses required in DS and IS\n",
    "'''\n",
    "MATCH (p1:Program {code: \"IS\"})-[:REQUIRES]->(course:Course),\n",
    "      (p2:Program {code: \"DS\"})-[:REQUIRES]->(course)\n",
    "RETURN course.code AS CourseCode, course.name AS CourseName\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6590-97e2-477f-b860-7ffd5fe63640",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "\n",
    "Write a Cypher query to retrieve the `course code`, `course title`, and the count of programs the course is a requirement in. Write as a Cypher query but retrieve the  output as a Spark Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b68985d-c57c-42b3-87a5-4b9c4b6114f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------+\n",
      "|CourseCode|         CourseTitle|ProgramCount|\n",
      "+----------+--------------------+------------+\n",
      "|    IST707|Applied Machine L...|           1|\n",
      "|    IST718|  Big Data Analytics|           1|\n",
      "|    IST687|Introduction to D...|           1|\n",
      "|    IST615|    Cloud Management|           2|\n",
      "|    IST659|Data Administrati...|           2|\n",
      "|    IST621|Information Manag...|           1|\n",
      "+----------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#16 Cypher to spark table\n",
    "\n",
    "# Define the Cypher query to retrieve course information and the count of programs that require each course\n",
    "cypher_query = \"\"\"\n",
    "MATCH (course:Course)<-[:REQUIRES]-(program:Program)\n",
    "RETURN course.code AS CourseCode, course.name AS CourseTitle, count(program) AS ProgramCount\n",
    "\"\"\"\n",
    "\n",
    "# Read the results of the Cypher query into a Spark DataFrame using the Neo4j Spark Connector\n",
    "programs_courses_df = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .option(\"url\", bolt_url)\\\n",
    "    .option(\"query\", cypher_query)\\\n",
    "    .load()\n",
    "\n",
    "# Display the DataFrame to verify contents\n",
    "programs_courses_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bc633",
   "metadata": {},
   "source": [
    "### Questions 17,18,19 and 20\n",
    "\n",
    "These are not spark questions as they use kibana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
